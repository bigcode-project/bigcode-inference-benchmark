# bigcode-inference-benchmark

BLOOM\
HF-accelerate\
A100 80GB

tokens/sec | msec/token
| batch_size |       fp32      | bf16 | int8<br>LLM.int8() |
|:----------:|:---------------:|:----:|:------------------:|
| 1          | 45.31 \| 22.07  |      |                    |
| 2          | 86.60 \| 11.55  |      |                    |
| 4          | 171.38 \| 5.83  |      |                    |
| 8          | 325.98 \| 3.07  |      |                    |
| 16         | 655.23 \| 1.53  |      |                    |
| 32         | 1356.57 \| 0.74 |      |                    |
| 64         | 2373.14 \| 0.42 |      |                    |
| 128        | 2688.91 \| 0.37 |      |                    |
| 256        | 3325.01 \| 0.30 |      |                    |
| 384        | 3261.28 \| 0.31 |      |                    |
| 512        | 3369.69 \| 0.30 |      |                    |
| 640        | 3506.41 \| 0.29 |      |                    |
| 768        | 3461.95 \| 0.29 |      |                    |
| 896        | 3346.01 \| 0.30 |      |                    |
| 1024       | oom             |      |                    |

sec
| batch_size |  fp32 | bf16 | int8<br>LLM.int8() |
|:----------:|:-----:|:----:|:------------------:|
| 1          | 2.21  |      |                    |
| 2          | 2.31  |      |                    |
| 4          | 2.33  |      |                    |
| 8          | 2.45  |      |                    |
| 16         | 2.44  |      |                    |
| 32         | 2.36  |      |                    |
| 64         | 2.70  |      |                    |
| 128        | 4.76  |      |                    |
| 256        | 7.70  |      |                    |
| 384        | 11.77 |      |                    |
| 512        | 15.19 |      |                    |
| 640        | 18.25 |      |                    |
| 768        | 22.18 |      |                    |
| 896        | 26.78 |      |                    |
| 1024       | oom   |      |                    |